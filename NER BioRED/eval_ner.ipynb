{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultil_ner import *\n",
    "from typing import Dict, List, Tuple\n",
    "from transformers import AutoModel, AutoConfig, AutoTokenizer, AutoModelForTokenClassification\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import torch\n",
    "from sklearn.metrics import classification_report\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# đưa đường dẫn model đã train và tokenizer vào\n",
    "model_path= '/media/data3/users/longnd/ehr-relation-extraction/biobert_ner/output/biobert__6class'\n",
    "tokenizer_path= '/media/data3/users/longnd/ehr-relation-extraction/biobert_ner/model/BiomedNLP-PubMedBERT-base-uncased-abstract'\n",
    "labels = get_labels()\n",
    "label_map = {i: label for i, label in enumerate(labels)}\n",
    "num_labels = len(labels)\n",
    "from ultil_ner import InputFeatures, open_pickle\n",
    "from tqdm import tqdm\n",
    "from torchcrf import CRF\n",
    "class BertCRFModel(nn.Module):\n",
    "    def __init__(self, config, model_name_or_path):\n",
    "        super(BertCRFModel, self).__init__()\n",
    "        self.bert = AutoModel.from_pretrained(model_name_or_path, config=config)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
    "        self.crf = CRF(config.num_labels, batch_first=True)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids, labels=None):\n",
    "        outputs = self.bert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids\n",
    "        )\n",
    "        sequence_output = outputs.last_hidden_state\n",
    "        sequence_output = self.dropout(sequence_output)\n",
    "        logits = self.classifier(sequence_output)\n",
    "        outputs = (logits,)\n",
    "        if labels is not None:\n",
    "            loss = self.crf(emissions = logits, tags=labels, mask=attention_mask.byte())\n",
    "            outputs =(-1*loss,)+outputs\n",
    "            return outputs \n",
    "        else:\n",
    "            return self.crf.decode(logits, attention_mask.byte())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultil_ner import InputFeatures, split_text_by_spacy_example\n",
    "from transformers import BertTokenizer\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from typing import List\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "\"\"\"\n",
    "các class cho mục đích test\n",
    "\"\"\"\n",
    "class NerDatasetForPredict(Dataset):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    features: List[InputFeatures]\n",
    "    pad_token_label_id: int = nn.CrossEntropyLoss().ignore_index\n",
    "\n",
    "    def __init__(self, features: List[InputFeatures]):\n",
    "        self.features = features\n",
    "        self.input_ids = [torch.tensor(example.input_ids).long() for example in self.features]\n",
    "        self.attention_masks = [torch.tensor(example.attention_mask).float() for example in self.features]\n",
    "        self.token_type_ids = [torch.tensor(example.token_type_ids).long() for example in self.features]\n",
    "        self.labels = [torch.tensor(example.label_ids).long() for example in self.features]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return {\n",
    "            \"input_ids\": self.input_ids[i],\n",
    "            \"attention_masks\": self.attention_masks[i],\n",
    "            \"token_type_ids\": self.token_type_ids[i],\n",
    "            \"labels\": self.labels[i],\n",
    "        }\n",
    "    \n",
    "# convert text to input for bert\n",
    "def convert_text_to_input_bert(text, tokenizer, labels_map, max_seq_length=512):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "        text: raw text\n",
    "        tokenizer: BertTokenizer\n",
    "        labels_map: dict{label: index}\n",
    "        max_seq_length: max length of input\n",
    "    Output:\n",
    "        sentences: list of sentences\n",
    "        sentences_input: list of InputFeatures for Bert Input\n",
    "    \"\"\"\n",
    "    sentences= split_text_by_spacy_example(text)\n",
    "    sentences_input= []\n",
    "    for sentence in sentences:\n",
    "        encoded_input = tokenizer.encode_plus(\n",
    "                    sentence,\n",
    "                    add_special_tokens=True,\n",
    "                    truncation=True,\n",
    "                    padding=\"max_length\",\n",
    "                    max_length= max_seq_length,\n",
    "                    return_attention_mask=True,\n",
    "                    return_token_type_ids=True)\n",
    "        input_ids = encoded_input[\"input_ids\"]\n",
    "        token_type_ids = encoded_input[\"token_type_ids\"]\n",
    "        attention_mask = encoded_input[\"attention_mask\"]\n",
    "        label_ids = ['O'] * len(input_ids)\n",
    "        label_ids= [labels_map[label] for label in label_ids]\n",
    "        assert len(input_ids) == max_seq_length\n",
    "        assert len(token_type_ids) == max_seq_length\n",
    "        assert len(attention_mask) == max_seq_length\n",
    "\n",
    "        sentences_input.append(InputFeatures(input_ids=input_ids, attention_mask=attention_mask, \n",
    "                                             token_type_ids=token_type_ids, label_ids=label_ids))\n",
    "    return sentences, sentences_input\n",
    "\n",
    "# predict BERT ko sử dụng CRF\n",
    "def predict(model, data_loader, label_map, device= 'cpu'):\n",
    "    '''Model: enity recognition\n",
    "    label_map: dict{index: label}\n",
    "    \n",
    "    Output:\n",
    "        preds_list: list of list of label of each sentence in B-I-O format\n",
    "        batch_preds: list of list of index of label of each sentence in digit format'''\n",
    "    model = model.to(device)\n",
    "    batch_preds = []\n",
    "    attention_masks = []\n",
    "    for batch in tqdm(data_loader):\n",
    "        with torch.no_grad():\n",
    "            outputs = model(batch['input_ids'].to(device), batch['attention_masks'].to(device), batch['token_type_ids'].to(device))\n",
    "            preds= np.argmax(outputs[0].detach().cpu().numpy(), axis=2)            \n",
    "            batch_preds.extend(preds)\n",
    "            attention_masks.extend(batch['attention_masks'].detach().cpu().numpy())\n",
    "    batch_size, seq_len = np.array(batch_preds).shape\n",
    "    preds_list = [[] for _ in range(batch_size)]\n",
    "\n",
    "    for i in range(batch_size): # số lượng câu chứ không phải batch-size nhé\n",
    "        for j in range(seq_len):\n",
    "            if attention_masks[i][j] != 0:\n",
    "                preds_list[i].append(label_map[batch_preds[i][j]])                   \n",
    "    return preds_list, batch_preds\n",
    "\n",
    "# predict BERT sử dụng CRF\n",
    "def predict_crf(model, data_loader, label_map, device= 'cpu'):\n",
    "    '''Model: enity recognition\n",
    "    label_map: dict{index: label}\n",
    "    \n",
    "    Output:\n",
    "        preds_list: list of list of label of each sentence in B-I-O format\n",
    "        batch_preds: list of list of index of label of each sentence in digit format'''\n",
    "    model = model.to(device)\n",
    "    batch_preds = []\n",
    "    attention_masks = []\n",
    "    for batch in tqdm(data_loader):\n",
    "        with torch.no_grad():\n",
    "            outputs = model(batch['input_ids'].to(device), batch['attention_masks'].to(device), batch['token_type_ids'].to(device))\n",
    "            preds = outputs[0]            \n",
    "            batch_preds.append(preds)\n",
    "            attention_masks.append(batch['attention_masks'].detach().cpu().numpy())\n",
    "    batch_size, seq_len = np.array(batch_preds).shape\n",
    "    preds_list = [[] for _ in range(batch_size)]\n",
    "\n",
    "    for i in range(batch_size): # số lượng câu chứ không phải batch-size nhé\n",
    "        for j in range(seq_len):\n",
    "            if attention_masks[i][j] != 0:\n",
    "                preds_list[i].append(label_map[batch_preds[i][j]])                   \n",
    "    return preds_list, batch_preds\n",
    "\n",
    "# predict đưa ra text cho model BERT ko sử dụng CRF\n",
    "def predict_example(model, text: str, tokenizer: BertTokenizer, labels, max_seq_length=512, device= 'cpu'):\n",
    "    \"\"\"label_map: \"\"\"\n",
    "    labels_map = {label: i for i, label in enumerate(labels)}\n",
    "    id2label = {i: label for label, i in labels_map.items()}\n",
    "    sentences, sentences_input= convert_text_to_input_bert(text, tokenizer, labels_map, max_seq_length)\n",
    "\n",
    "    test_data= NerDatasetForPredict(sentences_input)\n",
    "    data= DataLoader(test_data, batch_size= 8, shuffle= False, num_workers= 4)\n",
    "\n",
    "    preds_list, batch_preds= predict(model= model, data_loader= data, label_map= id2label, device= device)\n",
    "    batch_size, seq_len = np.array(batch_preds).shape\n",
    "    assert batch_size == len(sentences)\n",
    "    para= ''\n",
    "    result= []\n",
    "    for i in range(batch_size):\n",
    "        origin_token= tokenizer.tokenize(sentences[i], add_special_tokens=True) # token các từ\n",
    "        pred_token= preds_list[i] #[0: len(origin_token)] # nhãn của từng token\n",
    "        if i==0:\n",
    "            para+= tokenizer.decode(tokenizer.encode(sentences[i], add_special_tokens=False))\n",
    "        else:\n",
    "            para+=' '+ tokenizer.decode(tokenizer.encode(sentences[i], add_special_tokens=False))\n",
    "        entity_list= []\n",
    "        entity= ''\n",
    "        entity_type= ''\n",
    "        # bắt đầu lấy ra kết quả\n",
    "        for j in range(len(origin_token)):\n",
    "                # nếu pred là O thì lưu entity cũ và bỏ qua\n",
    "                if pred_token[j] == 'O':\n",
    "                    if entity != '':\n",
    "                        entity_list.append((entity, entity_type))\n",
    "                        entity = ''\n",
    "                        entity_type = ''\n",
    "                    continue\n",
    "                else:\n",
    "                    # bắt đầu bằng B-\n",
    "                    if pred_token[j].startswith('B-'):\n",
    "                        # đã có rồi thì thêm vào entity list\n",
    "                        if entity != '':\n",
    "                            entity_list.append((entity, entity_type))\n",
    "                            \n",
    "                        # gán cho biến mới\n",
    "                        entity = origin_token[j]\n",
    "                        if origin_token[j].startswith('##'):\n",
    "                            entity = origin_token[j][2:]\n",
    "                        entity_type = pred_token[j][2:]\n",
    "                        continue\n",
    "\n",
    "                    # nếu bắt đầu bằng I-\n",
    "                    elif pred_token[j].startswith('I-'):\n",
    "                        if entity != '' and entity_type == pred_token[j][2:]:\n",
    "                            if origin_token[j].startswith('##'):\n",
    "                                entity+= origin_token[j][2:]\n",
    "                            else:\n",
    "                                entity+=  ' '\n",
    "                                entity+=  origin_token[j]\n",
    "                            continue\n",
    "\n",
    "                        elif entity != '' and entity_type != pred_token[j][2:]:\n",
    "                            entity_list.append((entity, entity_type))\n",
    "                            entity = origin_token[j]\n",
    "                            if origin_token[j].startswith('##'):\n",
    "                                entity = origin_token[j][2:]                            \n",
    "                            entity_type = pred_token[j][2:]\n",
    "                            continue\n",
    "\n",
    "                        elif entity == '' and entity_type == '':\n",
    "                            entity = origin_token[j]\n",
    "                            if origin_token[j].startswith('##'):\n",
    "                                entity = origin_token[j][2:]\n",
    "                            entity_type = pred_token[j][2:]\n",
    "                            continue\n",
    "        result.extend(entity_list)\n",
    "    return result, para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "crf_model = False\n",
    "if not crf_model:\n",
    "    config = AutoConfig.from_pretrained( model_path, num_labels=num_labels, \n",
    "                                        id2label=label_map, label2id={label: i for i, label in enumerate(labels)})\n",
    "    tokenizer = AutoTokenizer.from_pretrained(tokenizer_path, cache_dir=None)\n",
    "    model = AutoModelForTokenClassification.from_pretrained(model_path, config=config)\n",
    "else:\n",
    "    labels = get_labels()\n",
    "    label_map: Dict[int, str] = {i: label for i, label in enumerate(labels)}\n",
    "    num_labels = len(labels)\n",
    "\n",
    "        # Load pretrained model and tokenizer\n",
    "    config = AutoConfig.from_pretrained(\n",
    "            model_path,\n",
    "            num_labels=num_labels,\n",
    "            id2label=label_map,\n",
    "            label2id={label: i for i, label in enumerate(labels)},\n",
    "    )\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "            model_path,\n",
    "            use_fast=False,\n",
    "    )\n",
    "\n",
    "    model= BertCRFModel(model_name_or_path=model_path, config=config)\n",
    "    # checkpoint của model đã train\n",
    "    model.load_state_dict(torch.load('/media/data3/users/longnd/ehr-relation-extraction/biobert_ner/output/pubmedbert-crf/epoch_7_f1_0.8817114093959733.pt'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "device= torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "def predict(model, data_loader, label_map, device= 'cpu'):\n",
    "    '''Model: enity recognition'''\n",
    "    model = model.to(device)\n",
    "    batch_preds = []\n",
    "    attention_masks = []\n",
    "    labels = []\n",
    "    for batch in tqdm(data_loader):\n",
    "        with torch.no_grad():\n",
    "            outputs = model(batch['input_ids'].to(device), batch['attention_masks'].to(device), batch['token_type_ids'].to(device))\n",
    "            preds= np.argmax(outputs[0].detach().cpu().numpy(), axis=2)            \n",
    "            batch_preds.extend(preds)\n",
    "            attention_masks.extend(batch['attention_masks'].detach().cpu().numpy())\n",
    "            labels.extend(batch['labels'].detach().cpu().numpy())\n",
    "    batch_size, seq_len = np.array(batch_preds).shape\n",
    "    preds_list = [[] for _ in range(batch_size)]\n",
    "    labels_list = [[] for _ in range(batch_size)]\n",
    "\n",
    "    for i in range(batch_size): # số lượng câu chứ không phải batch-size nhé\n",
    "        for j in range(seq_len):\n",
    "            if attention_masks[i][j] != 0:\n",
    "                preds_list[i].append(label_map[batch_preds[i][j]])  \n",
    "                labels_list[i].append(label_map[labels[i][j]])                 \n",
    "    return preds_list, batch_preds, labels_list\n",
    "\n",
    "id2label= {i:label for i, label in enumerate(get_labels())}\n",
    "def idtoLabel(pr, labels=id2label):\n",
    "    res= []\n",
    "    for i in pr:\n",
    "        res.append(labels[i])\n",
    "    return res\n",
    "def predict_crf(model, data_loader, label_map, device= 'cpu'):\n",
    "    '''Model: enity recognition'''\n",
    "    model = model.to(device)\n",
    "    batch_preds = []\n",
    "    labels = []\n",
    "    for batch in tqdm(data_loader):\n",
    "        with torch.no_grad():\n",
    "            outputs = model(batch['input_ids'].to(device), batch['attention_masks'].to(device), batch['token_type_ids'].to(device))\n",
    "            preds= outputs[0]  \n",
    "            assert len(preds)==sum(batch['attention_masks'][0].numpy().tolist())         \n",
    "            batch_preds.append(idtoLabel(preds))\n",
    "            labels.append(idtoLabel(batch['labels'].numpy().tolist()[0][0: len(preds)]))            \n",
    "    return batch_preds, labels\n",
    "\n",
    "def get_entity(pubtator_file: str, id:int,\n",
    "                not_use: List[str] =['OrganismTaxon', 'CellLine']):\n",
    "\n",
    "    with open(pubtator_file, 'r') as f: \n",
    "        pubtator_text = f.read()\n",
    "    annotations = {}\n",
    "    for line in pubtator_text.strip().split('\\n'):\n",
    "        fields = line.split('\\t')\n",
    "        if len(fields) ==1:\n",
    "            if fields[0]== '': \n",
    "                continue\n",
    "            pubmed_id, section, text = fields[0].split(\"|\")\n",
    "            if section == 't':\n",
    "                annotations[pubmed_id] = {'text': text, 'entities': []}\n",
    "            else:\n",
    "                annotations[pubmed_id]['text']+= \" \"+ text\n",
    "            continue\n",
    "        pmid = fields[0]\n",
    "        if pmid not in annotations:\n",
    "            annotations[pmid] = {'text': fields[2], 'entities': []}\n",
    "        if len(fields) == 6:\n",
    "            start, end = int(fields[1]), int(fields[2])\n",
    "            entity_type = fields[4]\n",
    "            if fields[4] in not_use:\n",
    "                continue\n",
    "            entity_text= fields[3]\n",
    "            assert annotations[pmid]['text'][start:end] == entity_text\n",
    "            annotations[pmid]['entities'].append((entity_text, entity_type))\n",
    "    return annotations[id]['text'], annotations[id]['entities']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 69/69 [00:12<00:00,  5.63it/s]\n"
     ]
    }
   ],
   "source": [
    "# đường dẫn tới file data test đã xử lý\n",
    "feature = open_pickle('/media/data3/users/longnd/ehr-relation-extraction/biobert_ner/data/Preprocess_BioBERT_6class/Test.pkl')\n",
    "test_dataset= NerDatasetForPredict(features=feature)\n",
    "\n",
    "label_map_id= {'GeneOrGeneProduct':0, 'DiseaseOrPhenotypicFeature':1, 'ChemicalEntity':2, 'SequenceVariant':3, 'OrganismTaxon':4, 'CellLine':5, 'O':6}\n",
    "label_map_new= {}\n",
    "for i in labels:\n",
    "    if i!= 'O':\n",
    "        label_map_new[i]= label_map_id[i[2:]]\n",
    "    else:\n",
    "        label_map_new[i]= label_map_id[i]\n",
    "id2id_new= {}\n",
    "for i in range(len(labels)):\n",
    "    id2id_new[i]= label_map_new[labels[i]]\n",
    "if not crf_model:\n",
    "    data= DataLoader(test_dataset, batch_size= 16, shuffle= False, num_workers= 4)\n",
    "    preds_list, batch_preds, label_list = predict(model, data, label_map, device)\n",
    "else:\n",
    "    data= DataLoader(test_dataset, batch_size= 1, shuffle= False, num_workers= 4)\n",
    "    batch_preds, label_list = predict_crf(model, data, label_map, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B-GeneOrGeneProduct': 0,\n",
       " 'I-GeneOrGeneProduct': 0,\n",
       " 'B-DiseaseOrPhenotypicFeature': 1,\n",
       " 'I-DiseaseOrPhenotypicFeature': 1,\n",
       " 'B-ChemicalEntity': 2,\n",
       " 'I-ChemicalEntity': 2,\n",
       " 'B-SequenceVariant': 3,\n",
       " 'I-SequenceVariant': 3,\n",
       " 'B-OrganismTaxon': 4,\n",
       " 'I-OrganismTaxon': 4,\n",
       " 'B-CellLine': 5,\n",
       " 'I-CellLine': 5,\n",
       " 'O': 6}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result(type_ent, preds_list, labels_list):\n",
    "    name= {i:[0, 0, 0] for i in type_ent}\n",
    "    name['all']= [0, 0, 0]\n",
    "    # tp, p_pred, p_true\n",
    "    for ent in name.keys():\n",
    "        for i in range(len(preds_list)):\n",
    "            if preds_list[i]==labels_list[i] and labels_list[i][2:]== ent:\n",
    "                name[ent][0]+=1\n",
    "            if labels_list[i][2:]== ent:\n",
    "                name[ent][2]+=1\n",
    "            if preds_list[i][2:]== ent:\n",
    "                name[ent][1]+=1  \n",
    "    for i in range(len(preds_list)):            \n",
    "        if preds_list[i]==labels_list[i] and labels_list[i][2:]!= 'O':\n",
    "            name['all'][0]+=1\n",
    "        if labels_list[i][2:]!= 'O':\n",
    "            name['all'][2]+=1\n",
    "        if preds_list[i][2:]!= 'O':\n",
    "            name['all'][1]+=1\n",
    "    \n",
    "\n",
    "    # tp, fp, tn, fn\n",
    "    for i in name.keys():\n",
    "        tp, p_pred, p_true= name[i]\n",
    "        pre= tp/(p_pred)\n",
    "        rec= tp/(p_true)\n",
    "        print(i)\n",
    "        print('     precision: ', tp/(p_pred))\n",
    "        print('     recall: ', tp/(p_true))\n",
    "        print('     f1: ', 2*pre*rec/(pre+rec))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Biobert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gán nhãn B và I của 1 thực thể là 1\n",
    "preds_list_new= []\n",
    "out_label_list_new= []\n",
    "for i in preds_list:\n",
    "    preds_list_new+=[label_map_new[j] for j in i]\n",
    "for i in label_list:\n",
    "    out_label_list_new+=[label_map_new[j] for j in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9480    0.9410    0.9445      4746\n",
      "           1     0.9192    0.9360    0.9275      3829\n",
      "           2     0.8787    0.9335    0.9053      2693\n",
      "           3     0.9745    0.9417    0.9578      1543\n",
      "           4     0.8899    0.9876    0.9362       483\n",
      "           5     0.9429    0.8777    0.9091       188\n",
      "           6     0.9863    0.9808    0.9835     34157\n",
      "\n",
      "    accuracy                         0.9689     47639\n",
      "   macro avg     0.9342    0.9426    0.9377     47639\n",
      "weighted avg     0.9695    0.9689    0.9691     47639\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# nhãn smooth\n",
    "print(classification_report(y_true=out_label_list_new,y_pred= preds_list_new, digits=4))#, target_names=label_map_id.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9377063920423063\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "print(f1_score(y_true=out_label_list_new,y_pred= preds_list_new, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9689330170658494\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "print(f1_score(y_true=out_label_list_new,y_pred= preds_list_new, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              precision    recall  f1-score   support\n",
      "\n",
      "                  B-CellLine     0.9556    0.8600    0.9053        50\n",
      "            B-ChemicalEntity     0.8866    0.9125    0.8993       754\n",
      "B-DiseaseOrPhenotypicFeature     0.8560    0.9008    0.8778       917\n",
      "         B-GeneOrGeneProduct     0.9388    0.9356    0.9372      1180\n",
      "             B-OrganismTaxon     0.9676    0.9873    0.9773       393\n",
      "           B-SequenceVariant     0.9643    0.8963    0.9290       241\n",
      "                  I-CellLine     0.9385    0.8841    0.9104       138\n",
      "            I-ChemicalEntity     0.8695    0.9350    0.9011      1939\n",
      "I-DiseaseOrPhenotypicFeature     0.9121    0.9190    0.9155      2912\n",
      "         I-GeneOrGeneProduct     0.9471    0.9389    0.9430      3566\n",
      "             I-OrganismTaxon     0.6593    0.9889    0.7911        90\n",
      "           I-SequenceVariant     0.9676    0.9416    0.9545      1302\n",
      "                           O     0.9863    0.9808    0.9835     34157\n",
      "\n",
      "                    accuracy                         0.9664     47639\n",
      "                   macro avg     0.9115    0.9293    0.9173     47639\n",
      "                weighted avg     0.9672    0.9664    0.9667     47639\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ko gán nhãn\n",
    "label_test= []\n",
    "for i in label_list:\n",
    "    label_test.extend(i)\n",
    "batch= []\n",
    "for i in preds_list:\n",
    "    batch.extend(i)\n",
    "# nhãn chính xác\n",
    "print(classification_report(y_true=label_test,y_pred= batch, digits=4))#, target_names=label_map_id.keys()\n",
    "# 0.915"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict(classification_report(y_true=label_test,y_pred= batch, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CellLine\n",
      "     precision:  0.9428571428571428\n",
      "     recall:  0.8776595744680851\n",
      "     f1:  0.9090909090909091\n",
      "DiseaseOrPhenotypicFeature\n",
      "     precision:  0.8981790202616056\n",
      "     recall:  0.914599112039697\n",
      "     f1:  0.9063146997929606\n",
      "OrganismTaxon\n",
      "     precision:  0.8899253731343284\n",
      "     recall:  0.9875776397515528\n",
      "     f1:  0.9362119725220805\n",
      "GeneOrGeneProduct\n",
      "     precision:  0.9450222882615156\n",
      "     recall:  0.9380530973451328\n",
      "     f1:  0.9415247964470763\n",
      "SequenceVariant\n",
      "     precision:  0.9671361502347418\n",
      "     recall:  0.9345430978613092\n",
      "     f1:  0.950560316413975\n",
      "ChemicalEntity\n",
      "     precision:  0.8741698706745893\n",
      "     recall:  0.928704047530635\n",
      "     f1:  0.9006121714079942\n",
      "all\n",
      "     precision:  0.966414072503621\n",
      "     recall:  0.966414072503621\n",
      "     f1:  0.966414072503621\n"
     ]
    }
   ],
   "source": [
    "get_result(set([i[2:] for i in get_labels() if i!='O']), batch, label_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### biobert focal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_list_new= []\n",
    "out_label_list_new= []\n",
    "for i in preds_list:\n",
    "    preds_list_new+=[label_map_new[j] for j in i]\n",
    "for i in label_list:\n",
    "    out_label_list_new+=[label_map_new[j] for j in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9236    0.9421    0.9327      4746\n",
      "           1     0.9218    0.9266    0.9242      3829\n",
      "           2     0.8922    0.9317    0.9115      2693\n",
      "           3     0.9604    0.9423    0.9513      1543\n",
      "           4     0.9856    0.9798    0.9827     34828\n",
      "\n",
      "    accuracy                         0.9678     47639\n",
      "   macro avg     0.9367    0.9445    0.9405     47639\n",
      "weighted avg     0.9682    0.9678    0.9680     47639\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# nhãn smooth\n",
    "print(classification_report(y_true=out_label_list_new,y_pred= preds_list_new, digits=4))#, target_names=label_map_id.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9404844018011438\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "print(f1_score(y_true=out_label_list_new,y_pred= preds_list_new, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              precision    recall  f1-score   support\n",
      "\n",
      "            B-ChemicalEntity     0.8893    0.9164    0.9027       754\n",
      "B-DiseaseOrPhenotypicFeature     0.8567    0.8931    0.8745       917\n",
      "         B-GeneOrGeneProduct     0.9020    0.9356    0.9185      1180\n",
      "           B-SequenceVariant     0.9500    0.8672    0.9067       241\n",
      "            I-ChemicalEntity     0.8885    0.9324    0.9099      1939\n",
      "I-DiseaseOrPhenotypicFeature     0.9170    0.9111    0.9140      2912\n",
      "         I-GeneOrGeneProduct     0.9248    0.9380    0.9314      3566\n",
      "           I-SequenceVariant     0.9498    0.9439    0.9468      1302\n",
      "                           O     0.9856    0.9798    0.9827     34828\n",
      "\n",
      "                    accuracy                         0.9652     47639\n",
      "                   macro avg     0.9182    0.9242    0.9208     47639\n",
      "                weighted avg     0.9657    0.9652    0.9654     47639\n",
      "\n"
     ]
    }
   ],
   "source": [
    "label_test= []\n",
    "for i in label_list:\n",
    "    label_test.extend(i)\n",
    "batch= []\n",
    "for i in preds_list:\n",
    "    batch.extend(i)\n",
    "# nhãn chính xác\n",
    "print(classification_report(y_true=label_test,y_pred= batch, digits=4))#, target_names=label_map_id.keys()\n",
    "# 0.915"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pubmed bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_list_new= []\n",
    "out_label_list_new= []\n",
    "for i in preds_list:\n",
    "    preds_list_new+=[label_map_new[j] for j in i]\n",
    "for i in label_list:\n",
    "    out_label_list_new+=[label_map_new[j] for j in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9503    0.9545    0.9524      2904\n",
      "           1     0.9211    0.8962    0.9085      2071\n",
      "           2     0.8987    0.9261    0.9122      1447\n",
      "           3     0.9861    0.9450    0.9651      1200\n",
      "           4     0.8844    0.9851    0.9321       404\n",
      "           5     0.8986    0.8732    0.8857       142\n",
      "           6     0.9879    0.9882    0.9880     28464\n",
      "\n",
      "    accuracy                         0.9759     36632\n",
      "   macro avg     0.9324    0.9383    0.9349     36632\n",
      "weighted avg     0.9761    0.9759    0.9760     36632\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# nhãn smooth\n",
    "print(classification_report(y_true=out_label_list_new,y_pred= preds_list_new, digits=4))#, target_names=label_map_id.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              precision    recall  f1-score   support\n",
      "\n",
      "                  B-CellLine     0.9362    0.8800    0.9072        50\n",
      "            B-ChemicalEntity     0.9028    0.9244    0.9135       754\n",
      "B-DiseaseOrPhenotypicFeature     0.8698    0.8811    0.8754       917\n",
      "         B-GeneOrGeneProduct     0.9432    0.9432    0.9432      1180\n",
      "             B-OrganismTaxon     0.9676    0.9873    0.9773       393\n",
      "           B-SequenceVariant     0.9487    0.9212    0.9347       241\n",
      "                  I-CellLine     0.8791    0.8696    0.8743        92\n",
      "            I-ChemicalEntity     0.8790    0.9120    0.8952       693\n",
      "I-DiseaseOrPhenotypicFeature     0.8978    0.8449    0.8705      1154\n",
      "         I-GeneOrGeneProduct     0.9482    0.9553    0.9517      1724\n",
      "             I-OrganismTaxon     0.2041    0.9091    0.3333        11\n",
      "           I-SequenceVariant     0.9869    0.9426    0.9643       959\n",
      "                           O     0.9879    0.9882    0.9880     28464\n",
      "\n",
      "                    accuracy                         0.9731     36632\n",
      "                   macro avg     0.8732    0.9199    0.8791     36632\n",
      "                weighted avg     0.9739    0.9731    0.9734     36632\n",
      "\n"
     ]
    }
   ],
   "source": [
    "label_test= []\n",
    "for i in label_list:\n",
    "    label_test.extend(i)\n",
    "batch= []\n",
    "for i in preds_list:\n",
    "    batch.extend(i)\n",
    "# nhãn chính xác\n",
    "print(classification_report(y_true=label_test,y_pred= batch, digits=4))#, target_names=label_map_id.keys()\n",
    "# 0.915"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CellLine\n",
      "     precision:  0.8985507246376812\n",
      "     recall:  0.8732394366197183\n",
      "     f1:  0.8857142857142857\n",
      "DiseaseOrPhenotypicFeature\n",
      "     precision:  0.884863523573201\n",
      "     recall:  0.8609367455335587\n",
      "     f1:  0.8727361722956438\n",
      "OrganismTaxon\n",
      "     precision:  0.8844444444444445\n",
      "     recall:  0.9851485148514851\n",
      "     f1:  0.9320843091334895\n",
      "GeneOrGeneProduct\n",
      "     precision:  0.9461775797051766\n",
      "     recall:  0.9504132231404959\n",
      "     f1:  0.9482906717058925\n",
      "SequenceVariant\n",
      "     precision:  0.9791304347826087\n",
      "     recall:  0.9383333333333334\n",
      "     f1:  0.9582978723404256\n",
      "ChemicalEntity\n",
      "     precision:  0.8913480885311871\n",
      "     recall:  0.9184519695922598\n",
      "     f1:  0.9046970728386657\n",
      "all\n",
      "     precision:  0.9731109412535488\n",
      "     recall:  0.9731109412535488\n",
      "     f1:  0.9731109412535488\n"
     ]
    }
   ],
   "source": [
    "get_result(set([i[2:] for i in get_labels() if i!='O']), batch, label_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pubmed smooth 6 class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_list_new= []\n",
    "out_label_list_new= []\n",
    "for i in preds_list:\n",
    "    preds_list_new+=[label_map_new[j] for j in i]\n",
    "for i in label_list:\n",
    "    out_label_list_new+=[label_map_new[j] for j in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9465    0.9566    0.9515      2904\n",
      "           1     0.9225    0.9029    0.9126      2071\n",
      "           2     0.8829    0.9219    0.9020      1447\n",
      "           3     0.9826    0.9425    0.9621      1200\n",
      "           4     0.8808    0.9876    0.9312       404\n",
      "           5     0.9528    0.8521    0.8996       142\n",
      "           6     0.9883    0.9871    0.9877     28464\n",
      "\n",
      "    accuracy                         0.9753     36632\n",
      "   macro avg     0.9366    0.9358    0.9353     36632\n",
      "weighted avg     0.9756    0.9753    0.9754     36632\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# nhãn smooth\n",
    "print(classification_report(y_true=out_label_list_new,y_pred= preds_list_new, digits=4))#, target_names=label_map_id.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              precision    recall  f1-score   support\n",
      "\n",
      "                  B-CellLine     0.9778    0.8800    0.9263        50\n",
      "            B-ChemicalEntity     0.8977    0.9191    0.9083       754\n",
      "B-DiseaseOrPhenotypicFeature     0.8713    0.8713    0.8713       917\n",
      "         B-GeneOrGeneProduct     0.9377    0.9432    0.9404      1180\n",
      "             B-OrganismTaxon     0.9605    0.9898    0.9749       393\n",
      "           B-SequenceVariant     0.9492    0.9295    0.9392       241\n",
      "                  I-CellLine     0.9390    0.8370    0.8851        92\n",
      "            I-ChemicalEntity     0.8525    0.9091    0.8799       693\n",
      "I-DiseaseOrPhenotypicFeature     0.8955    0.8614    0.8781      1154\n",
      "         I-GeneOrGeneProduct     0.9462    0.9594    0.9528      1724\n",
      "             I-OrganismTaxon     0.2083    0.9091    0.3390        11\n",
      "           I-SequenceVariant     0.9825    0.9374    0.9594       959\n",
      "                           O     0.9883    0.9871    0.9877     28464\n",
      "\n",
      "                    accuracy                         0.9724     36632\n",
      "                   macro avg     0.8774    0.9179    0.8802     36632\n",
      "                weighted avg     0.9733    0.9724    0.9728     36632\n",
      "\n"
     ]
    }
   ],
   "source": [
    "label_test= []\n",
    "for i in label_list:\n",
    "    label_test.extend(i)\n",
    "batch= []\n",
    "for i in preds_list:\n",
    "    batch.extend(i)\n",
    "# nhãn chính xác\n",
    "print(classification_report(y_true=label_test,y_pred= batch, digits=4))#, target_names=label_map_id.keys()\n",
    "# 0.915"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CellLine',\n",
       " 'ChemicalEntity',\n",
       " 'DiseaseOrPhenotypicFeature',\n",
       " 'GeneOrGeneProduct',\n",
       " 'OrganismTaxon',\n",
       " 'SequenceVariant'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([i[2:] for i in get_labels() if i!='O'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-GeneOrGeneProduct',\n",
       " 'I-GeneOrGeneProduct',\n",
       " 'B-DiseaseOrPhenotypicFeature',\n",
       " 'I-DiseaseOrPhenotypicFeature',\n",
       " 'B-ChemicalEntity',\n",
       " 'I-ChemicalEntity',\n",
       " 'B-SequenceVariant',\n",
       " 'I-SequenceVariant',\n",
       " 'B-OrganismTaxon',\n",
       " 'I-OrganismTaxon',\n",
       " 'B-CellLine',\n",
       " 'I-CellLine',\n",
       " 'O']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result(type_ent, preds_list, labels_list):\n",
    "    name= {i:[0, 0, 0] for i in type_ent}\n",
    "    name['all']= [0, 0, 0]\n",
    "    # tp, p_pred, p_true\n",
    "    for ent in name.keys():\n",
    "        for i in range(len(preds_list)):\n",
    "            if preds_list[i]==labels_list[i] and labels_list[i][2:]== ent:\n",
    "                name[ent][0]+=1\n",
    "            if labels_list[i][2:]== ent:\n",
    "                name[ent][2]+=1\n",
    "            if preds_list[i][2:]== ent:\n",
    "                name[ent][1]+=1  \n",
    "    for i in range(len(preds_list)):            \n",
    "        if preds_list[i]==labels_list[i] and labels_list[i][2:]!= 'O':\n",
    "            name['all'][0]+=1\n",
    "        if labels_list[i][2:]!= 'O':\n",
    "            name['all'][2]+=1\n",
    "        if preds_list[i][2:]!= 'O':\n",
    "            name['all'][1]+=1\n",
    "    \n",
    "\n",
    "    # tp, fp, tn, fn\n",
    "    for i in name.keys():\n",
    "        tp, p_pred, p_true= name[i]\n",
    "        pre= tp/(p_pred)\n",
    "        rec= tp/(p_true)\n",
    "        print(i)\n",
    "        print('     precision: ', tp/(p_pred))\n",
    "        print('     recall: ', tp/(p_true))\n",
    "        print('     f1: ', 2*pre*rec/(pre+rec))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChemicalEntity\n",
      "     precision:  0.8755790866975512\n",
      "     recall:  0.9143054595715273\n",
      "     f1:  0.894523326572008\n",
      "CellLine\n",
      "     precision:  0.952755905511811\n",
      "     recall:  0.852112676056338\n",
      "     f1:  0.8996282527881041\n",
      "DiseaseOrPhenotypicFeature\n",
      "     precision:  0.8845584607794771\n",
      "     recall:  0.8657653307580879\n",
      "     f1:  0.8750610053684724\n",
      "OrganismTaxon\n",
      "     precision:  0.8807947019867549\n",
      "     recall:  0.9876237623762376\n",
      "     f1:  0.9311551925320886\n",
      "GeneOrGeneProduct\n",
      "     precision:  0.9427597955706984\n",
      "     recall:  0.9528236914600551\n",
      "     f1:  0.9477650282582634\n",
      "SequenceVariant\n",
      "     precision:  0.9756733275412685\n",
      "     recall:  0.9358333333333333\n",
      "     f1:  0.955338153977031\n",
      "all\n",
      "     precision:  0.9724284778335881\n",
      "     recall:  0.9724284778335881\n",
      "     f1:  0.9724284778335881\n"
     ]
    }
   ],
   "source": [
    "get_result(set([i[2:] for i in get_labels() if i!='O']), batch, label_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### biobert smooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              precision    recall  f1-score   support\n",
      "\n",
      "                  B-CellLine     0.9767    0.8400    0.9032        50\n",
      "            B-ChemicalEntity     0.8559    0.8979    0.8764       754\n",
      "B-DiseaseOrPhenotypicFeature     0.8574    0.8855    0.8712       917\n",
      "         B-GeneOrGeneProduct     0.9118    0.9288    0.9202      1180\n",
      "             B-OrganismTaxon     0.9645    0.9669    0.9657       393\n",
      "           B-SequenceVariant     0.9638    0.8838    0.9221       241\n",
      "                  I-CellLine     0.9750    0.8478    0.9070       138\n",
      "            I-ChemicalEntity     0.8522    0.9216    0.8855      1939\n",
      "I-DiseaseOrPhenotypicFeature     0.9120    0.9179    0.9149      2912\n",
      "         I-GeneOrGeneProduct     0.9339    0.9358    0.9349      3566\n",
      "             I-OrganismTaxon     0.6581    0.8556    0.7440        90\n",
      "           I-SequenceVariant     0.9651    0.9332    0.9488      1302\n",
      "                           O     0.9851    0.9789    0.9820     34157\n",
      "\n",
      "                    accuracy                         0.9627     47639\n",
      "                   macro avg     0.9086    0.9072    0.9058     47639\n",
      "                weighted avg     0.9636    0.9627    0.9630     47639\n",
      "\n"
     ]
    }
   ],
   "source": [
    "label_test= []\n",
    "for i in label_list:\n",
    "    label_test.extend(i)\n",
    "batch= []\n",
    "for i in preds_list:\n",
    "    batch.extend(i)\n",
    "# nhãn chính xác\n",
    "print(classification_report(y_true=label_test,y_pred= batch, digits=4))#, target_names=label_map_id.keys()\n",
    "# 0.915"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChemicalEntity\n",
      "     precision:  0.853185595567867\n",
      "     recall:  0.9149647233568511\n",
      "     f1:  0.8829958788747536\n",
      "CellLine\n",
      "     precision:  0.9754601226993865\n",
      "     recall:  0.8457446808510638\n",
      "     f1:  0.905982905982906\n",
      "DiseaseOrPhenotypicFeature\n",
      "     precision:  0.8986591026302218\n",
      "     recall:  0.9101593105249413\n",
      "     f1:  0.904372648241858\n",
      "OrganismTaxon\n",
      "     precision:  0.8943248532289628\n",
      "     recall:  0.9461697722567288\n",
      "     f1:  0.9195171026156941\n",
      "GeneOrGeneProduct\n",
      "     precision:  0.9283769633507853\n",
      "     recall:  0.9340497260851243\n",
      "     f1:  0.9312047053880895\n",
      "SequenceVariant\n",
      "     precision:  0.9648648648648649\n",
      "     recall:  0.9254698639014906\n",
      "     f1:  0.944756864042342\n",
      "all\n",
      "     precision:  0.9627196204790193\n",
      "     recall:  0.9627196204790193\n",
      "     f1:  0.9627196204790193\n"
     ]
    }
   ],
   "source": [
    "get_result(set([i[2:] for i in get_labels() if i!='O']), batch, label_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pubmed + crf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              precision    recall  f1-score   support\n",
      "\n",
      "                  B-CellLine     0.9756    0.8000    0.8791        50\n",
      "            B-ChemicalEntity     0.8961    0.9151    0.9055       754\n",
      "B-DiseaseOrPhenotypicFeature     0.8677    0.8441    0.8557       917\n",
      "         B-GeneOrGeneProduct     0.9234    0.9398    0.9315      1180\n",
      "             B-OrganismTaxon     0.9420    0.9924    0.9665       393\n",
      "           B-SequenceVariant     0.8945    0.8797    0.8870       241\n",
      "                  I-CellLine     0.9577    0.7391    0.8344        92\n",
      "            I-ChemicalEntity     0.8688    0.8889    0.8787       693\n",
      "I-DiseaseOrPhenotypicFeature     0.9218    0.7868    0.8490      1154\n",
      "         I-GeneOrGeneProduct     0.9456    0.9269    0.9361      1724\n",
      "             I-OrganismTaxon     0.1923    0.9091    0.3175        11\n",
      "           I-SequenceVariant     0.9374    0.9364    0.9369       959\n",
      "                           O     0.9831    0.9882    0.9856     28464\n",
      "\n",
      "                    accuracy                         0.9675     36632\n",
      "                   macro avg     0.8697    0.8882    0.8587     36632\n",
      "                weighted avg     0.9681    0.9675    0.9675     36632\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# batch_preds, label_list\n",
    "label_test= []\n",
    "for i in label_list:\n",
    "    label_test.extend(i)\n",
    "batch= []\n",
    "for i in batch_preds:\n",
    "    batch.extend(i)\n",
    "# nhãn chính xác\n",
    "print(classification_report(y_true=label_test,y_pred= batch, digits=4))#, target_names=label_map_id.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36632"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SequenceVariant\n",
      "     precision:  0.9288702928870293\n",
      "     recall:  0.925\n",
      "     f1:  0.9269311064718162\n",
      "GeneOrGeneProduct\n",
      "     precision:  0.9363542026980284\n",
      "     recall:  0.9321625344352618\n",
      "     f1:  0.934253666954271\n",
      "ChemicalEntity\n",
      "     precision:  0.8830290736984449\n",
      "     recall:  0.902557014512785\n",
      "     f1:  0.8926862611073137\n",
      "CellLine\n",
      "     precision:  0.9642857142857143\n",
      "     recall:  0.7605633802816901\n",
      "     f1:  0.8503937007874015\n",
      "OrganismTaxon\n",
      "     precision:  0.8583690987124464\n",
      "     recall:  0.9900990099009901\n",
      "     f1:  0.9195402298850576\n",
      "DiseaseOrPhenotypicFeature\n",
      "     precision:  0.8961108151305275\n",
      "     recall:  0.8121680347658136\n",
      "     f1:  0.8520770010131712\n",
      "all\n",
      "     precision:  0.9674874426730727\n",
      "     recall:  0.9674874426730727\n",
      "     f1:  0.9674874426730727\n"
     ]
    }
   ],
   "source": [
    "get_result(set([i[2:] for i in get_labels() if i!='O']), batch, label_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### biobert + crf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              precision    recall  f1-score   support\n",
      "\n",
      "                  B-CellLine     0.9744    0.7600    0.8539        50\n",
      "            B-ChemicalEntity     0.9008    0.9151    0.9079       754\n",
      "B-DiseaseOrPhenotypicFeature     0.8749    0.8691    0.8720       917\n",
      "         B-GeneOrGeneProduct     0.9221    0.9331    0.9275      1180\n",
      "             B-OrganismTaxon     0.9652    0.9873    0.9761       393\n",
      "           B-SequenceVariant     0.8943    0.9129    0.9035       241\n",
      "                  I-CellLine     0.9815    0.7681    0.8618       138\n",
      "            I-ChemicalEntity     0.8920    0.9371    0.9140      1939\n",
      "I-DiseaseOrPhenotypicFeature     0.9342    0.8929    0.9131      2912\n",
      "         I-GeneOrGeneProduct     0.9401    0.9204    0.9301      3566\n",
      "             I-OrganismTaxon     0.6984    0.9778    0.8148        90\n",
      "           I-SequenceVariant     0.9505    0.9301    0.9402      1302\n",
      "                           O     0.9816    0.9846    0.9831     34157\n",
      "\n",
      "                    accuracy                         0.9650     47639\n",
      "                   macro avg     0.9162    0.9068    0.9075     47639\n",
      "                weighted avg     0.9652    0.9650    0.9649     47639\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# batch_preds, label_list\n",
    "label_test= []\n",
    "for i in label_list:\n",
    "    label_test.extend(i)\n",
    "batch= []\n",
    "for i in batch_preds:\n",
    "    batch.extend(i)\n",
    "# nhãn chính xác\n",
    "print(classification_report(y_true=label_test,y_pred= batch, digits=4))#, target_names=label_map_id.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47639"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrganismTaxon\n",
      "     precision:  0.9015151515151515\n",
      "     recall:  0.9855072463768116\n",
      "     f1:  0.9416419386745797\n",
      "CellLine\n",
      "     precision:  0.9795918367346939\n",
      "     recall:  0.7659574468085106\n",
      "     f1:  0.8597014925373134\n",
      "DiseaseOrPhenotypicFeature\n",
      "     precision:  0.9195993502977802\n",
      "     recall:  0.8871768085662053\n",
      "     f1:  0.9030971686827063\n",
      "GeneOrGeneProduct\n",
      "     precision:  0.935538954108858\n",
      "     recall:  0.9235145385587863\n",
      "     f1:  0.9294878591877849\n",
      "SequenceVariant\n",
      "     precision:  0.9414473684210526\n",
      "     recall:  0.9274141283214518\n",
      "     f1:  0.9343780607247796\n",
      "ChemicalEntity\n",
      "     precision:  0.8943988583660364\n",
      "     recall:  0.9309320460453027\n",
      "     f1:  0.9122998544395925\n",
      "all\n",
      "     precision:  0.9649656793803396\n",
      "     recall:  0.9649656793803396\n",
      "     f1:  0.9649656793803396\n"
     ]
    }
   ],
   "source": [
    "get_result(set([i[2:] for i in get_labels() if i!='O']), batch, label_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### code for report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "text= \"Founder mutations in the BRCA1 gene.\"\n",
    "tokenizer= AutoTokenizer.from_pretrained('/media/data3/users/longnd/ehr-relation-extraction/biobert_ner/model/biobert-v1.1', cache_dir=None)\n",
    "tok= tokenizer.tokenize(text, add_special_tokens=True)\n",
    "tok_pad= tokenizer.encode(text, add_special_tokens=True, max_length=20, padding='max_length', truncation=True)\n",
    "tok1= tokenizer.encode(text, add_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  Founder mutations in the BRCA1 gene.\n",
      "Tokenized:  ['Founder', 'mutations', 'in', 'the', 'BR', '##CA', '##1', 'gene', '.']\n",
      "Tokenized using padding:  ['[CLS]', 'Founder', 'mutations', 'in', 'the', 'BR', '##CA', '##1', 'gene', '.', '[SEP]', '[PAD]', '[PAD]']\n",
      "Token IDs:  [101, 16505, 17157, 1107, 1103, 26660, 11356, 1475, 5565, 119, 102, 0, 0]\n",
      "Attention Mask:  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print('Original: ', text)\n",
    "print('Tokenized: ', tokenizer.tokenize(text))\n",
    "print('Tokenized using padding: ', tokenizer.tokenize(text, add_special_tokens=True, max_length=13, padding='max_length', truncation=True))\n",
    "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(text, add_special_tokens=True, max_length=13, padding='max_length', truncation=True)))\n",
    "print('Attention Mask: ', tokenizer.encode_plus(text, add_special_tokens=True, max_length=13, padding='max_length', truncation=True)['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from colorama import init, Fore, Back, Style\n",
    "\n",
    "# Initialize colorama to enable ANSI color codes on Windows\n",
    "init()\n",
    "\n",
    "# Function to print colored text\n",
    "def print_colored_text(text, color='white', background=None, style=None):\n",
    "    color_code = getattr(Fore, color.upper(), Fore.WHITE)\n",
    "    background_code = getattr(Back, background.upper(), '')\n",
    "    style_code = getattr(Style, style.upper(), '')\n",
    "\n",
    "    colored_text = f\"{style_code}{background_code}{color_code}{text}{Style.RESET_ALL}\"\n",
    "    print(colored_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Founder mutations in the BRCA1 gene in Polish families with breast-ovarian cancer.\n"
     ]
    }
   ],
   "source": [
    "print_colored_text(text,background='blue', color='green', style='underline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Congenital\tB-Disease\n",
      "hypothyroidism\tI-Disease\n",
      "due\tO\n",
      "to\tO\n",
      "a\tO\n",
      "new\tO\n",
      "deletion\tO\n",
      "in\tO\n",
      "the\tO\n",
      "sodium/iodide\tB-Disease\n",
      "symporter\tI-Disease\n",
      "protein.\tI-Disease\n"
     ]
    }
   ],
   "source": [
    "def print_bio_tags(sentence, bio_tags):\n",
    "    words = sentence.split()\n",
    "    tags = bio_tags.split()\n",
    "\n",
    "    for word, tag in zip(words, tags):\n",
    "        print(f\"{word}\\t{tag}\")\n",
    "\n",
    "# Example usage\n",
    "sentence = \"Congenital hypothyroidism due to a new deletion in the sodium/iodide symporter protein.\"\n",
    "bio_tags = \"B-Disease I-Disease O O O O O O O B-Disease I-Disease I-Disease\"\n",
    "\n",
    "print_bio_tags(sentence, bio_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  Congenital hypothyroidism due to a new deletion in the sodium/iodide symporter protein.\n",
      "Labels:  B-Disease I-Disease O O O O O O O B-Disease I-Disease I-Disease\n"
     ]
    }
   ],
   "source": [
    "print(\"Original: \", sentence)\n",
    "print(\"Labels: \", bio_tags)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
